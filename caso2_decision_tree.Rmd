---
title: "title"
author: "author"
output:
  html_document:
    df_print: paged
    highlight: kate
    theme:
      version: 4
      code_font: 
        google: JetBrains Mono
editor_options:
  chunk_output_type: console
  markdown:
    wrap: 72
---
# init 

```{r echo = F}
library(tidyverse)
library(tidymodels)
library(corrr)
theme_set(theme_classic())
```

Al cargar los datos especificamos el separador de celdas y de decimales, para parsear correctamente el archivo.

```{r}
churn <- read_delim("churn.csv",
  delim = ";",
  locale = locale(decimal_mark = ",")
) %>%
  janitor::clean_names()
```

# miramos variables

Primero calculamos un resumen general. Vemos que no tenemos datos missing. Dentro de las
numéricas, el `area_code` no es realmente numérica. Por lo cual la cambiamos a factor.
Además, arreglamos la variable `churn`, que es un string feo. 

```{r}
churn %>% 
  mutate(area_code = factor(area_code),
         churn = str_detect(churn, stringr::fixed("true", ignore_case = T)),
         state = factor(state)) -> churn

churn %>% skimr::skim()
```

## correlaciones

Miramos correlaciones de las variables numéricas mediante un correlograma. En la diagonal
tenemos correlación perfecta, obviamente, pero además hay un par de variables altamente correlacionadas:
los cargos con la cantidad de minutos. Esto es esperable, ya que el cargo es proporcional a la cantidad 
de minutos (escalando por el precio del minuto según la categoría, día/tarde/noche/internacional). Eliminamos las variables de cargos, eligiéndola arbitrariamente.

Con respecto a las otras, no hay correlaciones (nótese todo el correlograma en blanco = 0)

```{r}
churn %>%
  select(where(is.numeric)) %>% 
  # seteamos la diagonal a 1 para evitar artefactos
  correlate(diagonal = 1) %>% 
  rearrange() %>% 
  shave() %>% 
  rplot() + theme(axis.text.x = element_text(angle = 45, hjust = 1))

churn %>% select(-ends_with("charge")) -> churn
```

## distribuciones

Para mirar las distribuciones tenemos que mover un poco la tabla. Para eso pivoteamos.
No parece haber cosas extrañas. La mayoría de las variables son aproximadamente normales,
salvo algunas (`cust_serv_calls`, `intl_calls`) que son asimétricas positivas, y `vmail_message`, que
es bimodal (en particular, la gran mayoría de los valores es cero).

```{r}
churn %>%
  select(where(is.numeric)) %>%
  pivot_longer(cols = everything(), names_to = "var", values_to = "value") %>%
  ggplot(aes(value)) +
  geom_histogram(alpha = 0.3, bins = 20) +
  facet_wrap(~var, scales = "free")
```

Mirando con más detalle `vmail_message`, eliminando las observaciones 0, vemos que
tiene forma acampanada.

```{r}
churn %>% 
  filter(vmail_message != 0) %>% 
  ggplot(aes(vmail_message)) + geom_histogram(alpha = 0.3, binwidth = 1)
```

Para corroborar, podemos hacer qqplots. Corroboramos que todas las variables, salvo
`cust_serv_calls` e `intl_calls` son aproximadamente normales. 

```{r}
churn %>%
  select(where(is.numeric)) %>%
  pivot_longer(cols = everything(), names_to = "var", values_to = "value") %>%
  filter(!(var == "vmail_message" & value == 0)) %>% 
  ggplot(aes(sample = value)) + 
  geom_qq(size = .1) + geom_qq_line() + facet_wrap(~var, scales = "free")
```

Por último, podemos separar (coloreando) las distribuciones de las numéricas por `churn`,
para ver si hay asociaciones. Vemos que la mayoría de las distribuciones son similares, salvo
`day_mins`, y `cust_serv_calls.` Parece que hay una subpoblación de churners que hablan mas cantidad de minutos durante el día.

Con respecto a `cust_serv_calls`, parece un poco bimodal en los clientes que churnean, mientras
que en los que no parece unimodal. Los picos que se ven en la densidad son artefactos
causados por dos cosas, la alta cantidad de datos y que es una variable discreta; en los
churners no se ven porque son pocos datos, y la estimación de la densidad no es "tan buena".

```{r}
churn %>%
  select(where(is.numeric), churn) %>%
  pivot_longer(cols = -churn, names_to = "var", values_to = "value") %>% 
  ggplot(aes(value, color = churn, fill = churn)) +
  geom_density(alpha = 0.3) +
  #geom_histogram(alpha = 0.3) +
  facet_wrap(~var, scales = "free")
```

Otra forma de graficar las distribuciones es como boxplots, separndo por churn.
Esto permite ver un poco mejor que hay una (pequeña) diferencia en las variables de minutos.

```{r}
churn %>%
  select(where(is.numeric), churn) %>%
  pivot_longer(cols = -churn, names_to = "var", values_to = "value") %>% 
  ggplot(aes(churn, value, color = churn)) +
  geom_boxplot()+
  facet_wrap(~var, scales = "free")
```


## categóricas

Graficamos las proporciones de churn en los niveles de las diferentes variables categóricas.
Vemos que no hay asociación con respecto al area_code. Por otro lado, los clientes con intl_plan son
mas propensos a churnear. Por último, con respecto a vmail_plan, los clientes sin vmail_plan tienden a churnear un poco más, pero la diferencia es pequeña. 

```{r}
churn %>% 
  select(area_code, intl_plan, vmail_plan, churn) %>% 
  pivot_longer(cols = -churn, names_to = "var", values_to = "level") %>%
  count(var, level, churn) %>% 
  group_by(var, level) %>% 
  mutate(total_per_level = sum(n),
         prop_churn = n / total_per_level) %>% 
  
  ggplot(aes(level, prop_churn, fill = churn)) +
  geom_col() +
  facet_wrap(~var, scales = "free_x")
  
```

Con respecto al estado de residencia, lo miramos independientemente, ya que posee
alta cardinalidad y se ensucian las figuras. Graficando la proporcion de churn por estado
vemos que hay diferencias entre estados. Podemos explorar por region graficando un mapa!

```{r}
churn %>% 
  count(state, churn) %>% 
  group_by(state) %>% 
  mutate(total_per_state = sum(n),
         prop_churn = n / total_per_state,
         # creo columna para ordenar (necesito 1 elemento por nivel!)
         order = prop_churn[churn == TRUE]) %>% ungroup() -> churn_state

churn_state %>% 
  # reordeno state via la columna de orden
  ggplot(aes(x = fct_reorder(state, order), y = prop_churn, fill = churn)) +
  geom_col()
```

No vemos una asociacion regional muy marcada con respecto a la probabilidad de churn.
Quiza en la costa oeste y noreste la probabilidad es un poco mayor. Mientras que 
el interior del pais tiende a ser mas oscuro. Pero hay excepciones.

Vale aclarar que no nos especializamos (aun) en analisis geografico (ni mucho menos),
por lo que desconocemos las potenciales sutilezas en la representación e interpretación. 
Pero nos pareció un lindo experimento.

```{r}

# cargo tabla para graficar mapa
us <- map_data("state")

# necesito los codigos de dos letras de los estados
state_code <- tibble(state = state.abb,
                     state_name = tolower(state.name))
# junto los codigos en la tabla del mapa
us %>%
  left_join(state_code, by = c("region" = "state_name")) -> us

# defino un theme lindo para el mapa, sacando todas las lineas y textos
theme_mapa <- theme_minimal() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.text = element_blank(),
    axis.title = element_blank()
  )

churn_state %>%
  select(state, churn, prop_churn) %>% 
  pivot_wider(names_from = churn, values_from = prop_churn, names_prefix = "churn_") %>% 
  #mutate(log_odds = log(churn_TRUE / churn_FALSE)) %>% 
  right_join(us, by = "state") %>% 
  
  ggplot(aes(fill = churn_TRUE)) + 
  # importante el group para que las lineas del mapa queden unidas por estado
  geom_polygon(aes(long, lat, group = group), color = "black") +
  scale_fill_viridis_c() +
  coord_map() + 
  
  ggtitle("probabilidad de churn por estado") +
  theme_mapa
```

# modelado

Primero particionamos los datos en train/test.

```{r}
churn %>% 
  mutate(churn = factor(churn)) -> churn

set.seed(231)
churn_split <- initial_split(churn, prop = 0.80,
                             strata = churn)

churn_train <- training(churn_split)

churn_test <- testing(churn_split)

churn_folds <- vfold_cv(churn_train, v = 5, strata = churn)
```

Ademas definimos una funcion con las metricas de performance que nos interesan
para evaluar la optimizacion de hiperparametros.

```{r}
churn_metrics <- metric_set(accuracy, sens, spec, roc_auc)
```

Definimos receta de preprocesamiento. Para un arbol no hay que hacer mucho, unicamente
especificar la formula para el modelado: queremos predecir churn en funcion de todas
las otras variables.

```{r}
rec_dt <- recipe(churn ~ ., churn_train) #%>% 
  #update_role(phone, new_role = "id variable")
```

Definimos el modelo, con parametros a tunear

```{r}
tree_model_tune <- decision_tree(tree_depth = tune(),
                                 cost_complexity = tune(),
                                 min_n = tune()) %>% 
  set_engine("rpart") %>% 
  set_mode("classification")
```

Juntamos todo en un workflow: receta de preprocessing + modelo

```{r}
dt_tune_wkfl <- workflow() %>%
  add_recipe(rec_dt) %>%
  add_model(tree_model_tune)
```

Necesitamos una forma de samplear el espacio de parametros a explorar, para lo que 
armamos una grilla regular (en parte porque permite una visualización mas cómoda
de los resultados, contra latin hypercube sampling por ejemplo, gracias a que se
repiten los valores de los parámetros)

```{r}
#dt_tune_grid <- grid_latin_hypercube(parameters(dt_tune_wkfl), size = 20)
set.seed(312)
dt_tune_grid <- grid_regular(parameters(dt_tune_wkfl), levels = 5)
```

Tuneamos el modelo

```{r}

cl <- parallel::makePSOCKcluster(8)
doParallel::registerDoParallel(cl, cores = 8)

set.seed(123)
# tuneo
#tic()
dt_tuning <- tune_grid(dt_tune_wkfl,
                       resamples = churn_folds,
                       grid = dt_tune_grid,
                       metrics = churn_metrics)
#toc()
#beepr::beep("coin")
```

Graficamos los resultados y nos encontramos con que no importa el valor de los parámetros
explorados, todas las medidas de performance dan iguales. Este resultado desde ya es extraño
así que decidimos estudiar un poco más la cuestión.

```{r}
autoplot(dt_tuning)
```

Nos quedamos con "el mejor modelo" (por quedarnos con uno, porque dan todos practicamente idénticos)
usando el área bajo la curva ROC. Vemos que es un modelo super "complejo" (cost_complexity ~ 0), pocos 
datos por nodo, pero con una profundidad de 1. Es decir, un solo split, lo cual nos hizo mas ruido.

```{r}
# dt_tuning %>%
#   collect_metrics() %>%
#   arrange(.metric, desc(mean))

best_dt_params <- dt_tuning %>%
  select_best(metric = "roc_auc")

best_dt_params
```

Finalizamos el workflow, usando este set de párametros. Luego corremos el ultimo
fit con todo el training set (sin hacer cross-validation), y calculamos las métricas
con el test set (esta separación es automática, con la función last_fit)

```{r}
dt_tune_final_wkfl <- dt_tune_wkfl %>% 
  finalize_workflow(best_dt_params)

tree_model <- dt_tune_final_wkfl %>% 
  last_fit(churn_split)

tree_model %>% collect_metrics()

```

Luego extraemos el modelo para explorarlo un poco mejor, usando el paquete vip, para 
graficar la importancia de los predictores en la predicción.
Y acá encontramos el problema (después de horas de debugging, pensando que el error
estaba en el código): Estamos usando la variable phone para clasificar! lo cual no tiene
sentido ya que es una variable de ID. 

```{r}
tree_fit <- tree_model %>% 
            extract_fit_parsnip()

vip::vip(tree_fit)

```

La eliminamos y repetimos el proceso de tuning:

```{r}
rec_dt_no_phone <- recipe(churn ~ ., churn_train) %>% 
  update_role(phone, new_role = "id variable")

  
dt_tune_wkfl_no_phone <- workflow() %>%
  add_recipe(rec_dt_no_phone) %>%
  add_model(tree_model_tune)
  

cl <- parallel::makePSOCKcluster(8)
doParallel::registerDoParallel(cl, cores = 8)

set.seed(123)
# tuneo
#tic()
dt_tuning_no_phone <- tune_grid(dt_tune_wkfl_no_phone,
  resamples = churn_folds,
  grid = dt_tune_grid,
  metrics = churn_metrics
)
#toc()
#beepr::beep("coin")
```

Y graficamos los resultados, ahora si, viendo como varia la performance al modificar los parámetros.

```{r}
dt_tuning_no_phone %>%
  autoplot()
```

Luego nos quedamos con el mejor set de parámetros según la el área bajo ROC.

```{r}
best_dt_params_no_phone <- dt_tuning_no_phone %>%
  select_best(metric = "roc_auc")

best_dt_params_no_phone

```

Fitteamos, y evaluamos en test.

```{r}
dt_tune_final_wkfl_no_phone <- dt_tune_wkfl_no_phone %>% 
  finalize_workflow(best_dt_params_no_phone)

tree_model_no_phone <- dt_tune_final_wkfl_no_phone %>% 
  last_fit(churn_split)

tree_model_no_phone %>% collect_metrics()

```

Por último, graficamos la importancia de las variables. Vemos que la variable mas
importante en la clasificacion es la cantidad de minutos hablados en el día.

```{r}
tree_fit_no_phone <- tree_model_no_phone %>% 
            extract_fit_parsnip()

vip::vip(tree_fit_no_phone)

```

